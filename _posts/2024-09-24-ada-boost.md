---
title: "Boosting: AdaBoost"
author: Andrew Benedict
date: 2024-09-24
category: Jekyll
layout: post
---

> **Lưu ý**
>
> Một số thuật ngữ liên quan đến thuật toán trong bài viết này sẽ không được dịch ra tiếng Việt
{:.block-warning}

# 1. Khái niệm về Adaptive Boosting (AdaBoost)
Giả sử bạn đang ôn môn Toán cho kì thi cuối kỳ. Trong lúc ôn thi bạn sẽ giải sai một số bài toán (khó), bạn sẽ làm gì tiếp theo? Tôi tin rằng đa phần sẽ xem lại hoặc làm lại bài toán đó cho tới khi hiểu và giải đúng, đó cũng chính là chiến thuật mà thuật toán Adaptive Boosting sử dụng. "Adaptive" mang nghĩa *thích nghi* hoặc *thích ứng*, ám chỉ base learner của model sẽ dần dần học và hiệu chỉnh theo các sai sót trong quá trình training ở vòng lặp trước đó. Từ từ đã, thuật toán học máy nào mà chẳng hiệu chỉnh để học tốt hơn? Thật ra, với AdaBoost thì từ *adaptive* mang nghĩa đen nhiều hơn khi nó học bám sát theo từng sample mà nó dự đoán sai ở vòng lặp trước đó. Nếu bạn đọc đã xem bài viết trước về Random Forest (RF) thì sẽ biết được có 2 điểm nổi bật của RF. Đó là *huấn luyện song song* và học trên bộ dữ liệu *thu thập ngẫu nhiên có lặp lại (bootstrapping)*. Điều này dẫn đến 2 vấn đề tương ứng mà AdaBoost giải quyết được:
   1. Huấn luyện song song bắt buộc mọi base learner không học được gì lẫn nhau. Lỗi ở learner này có thể gặp lại ở nhiều learners khác.
   2. Bootstrapping không đảm bảo model sẽ giải quyết được những samples mà base learner không học tốt.

AdaBoost chứa các yếu tố có thể giải quyết được 2 vấn đề này cũng như học tốt trên nhiều loại dataset khác nhau.

## 1.1 Kĩ thuật Boosting
Nếu như RF sử dụng kĩ thuật *bagging* làm mấu chốt, thì với AdaBoost ta biết được thêm một nhánh của kĩ thuật *ensemble* đó là *boosting*. Boosting là quá trình ta xây dựng một base learner mới hoặc phát triển thêm base learner đang có dựa trên lỗi hoặc kết quả từ base learner ở vòng lặp trước đó.Nói cách khác, learner thứ $m$ sẽ học dựa trên sai sót của learner thứ $m-1$ hoặc toàn bộ learners trước đó. Các thuật toán dựa trên boosting vì tính chất này mà các learners được xây dựng một cách **tuần tự**. Hệ quả là, trên lý thuyết, các learners được tạo sau sẽ khắc phục được lỗi của learners trước chúng và tựu chung toàn bộ model sẽ đạt kết quả tốt hơn. AdaBoost nổi tiếng với việc vào thời điểm đó là thuật toán có thể dùng một tập hợp các **weak** learners, những learners có kết quả chỉ tốt hơn dự đoán ngẫu nhiên, mà có thể đạt được kết quả của một classifier mạnh.

> **Lưu ý**
>
> Việc sử dụng strong learner làm base learner về mặt lý thuyết vẫn hoạt động. Nhưng model sẽ phải được điều chỉnh khác vì các learners quá mạnh có thể dẫn đến overfitting. Ngoài ra, tại sao phải boost learners mạnh khi nó đã đủ "mạnh" và việc boost weak learners nhanh hơn?
{:.block-warning}


## 1.2. Đánh trọng số mẫu dữ liệu
Với bài Decision Tree trước thì tôi giả định ta không sử dụng *sample weights* (trọng số mẫu dữ liệu) có thể điều chỉnh được bằng biến `sample_weight` trong hàm `fit`. Hay nói cách khác, là ta xem giá trị của mỗi sample là như nhau. Tuy nhiên, sample weights có thể được chỉnh để ảnh hưởng tới giá trị của sample cũng như thay đổi giá trị tách node của cây. Giả sử trong bài toán classification có 2 class $k$ là `0` và `1` với bộ dữ liệu có $N$ điểm, thông thường khi ta tính Gini Impurity cho 1 node $Q$ bất kì và hiện tại đang có $M$ điểm dữ liệu tại node đó thì công thức sẽ là:

$$
    Gini(Q) = 1 - \sum_{k=0}^{1} \sum_{i=1}^{M} \dfrac{1}{M} I(G(x_i)=k)
$$

trong đó $G(x_i)$ trả về class của điểm dữ liệu đó và hàm $I(G(x_i)=k)$ trả về $0$ nếu $x_i$ không thuộc class $k$ và $1$ nếu thuộc class $k$. Như vậy thì công thức thông thường này xem mọi sample có giá trị bằng nhau với việc ta sử dụng $\dfrac{1}{M}$ là giá trị của từng sample. Nếu ta sử dụng sample weights với một array $W$ tương ứng với $w_1$ chứa weight của $x_1$, $w_n$ cho weight của $x_n$ và $\sum_{i=1}^{N}w_i=1$. Như vậy công thức tính Gini mới sẽ là:

$$
    Gini(Q) = 1 - \sum_{k=0}^{1} \sum_{i=1}^{M} w_i I(G(x_i)=k)
$$

Như vậy, khi ta thay đổi sample weight cho một số samples thì cách chọn node của cây cũng bị ảnh hưởng, giả sử ta thay đổi sample weight sao cho class `0` có tổng weight lớn hơn class `1` rất nhiều dù số lượng ít hơn thì Gini cũng sẽ bị thay đổi đáng kể. Nói cách khác, qua sample weight ta có thể làm model chú ý hơn tới những sample "đặc biệt" này. AdaBoost chính xác là dự vào cơ chế này để giúp cây sau hoạt động tốt hơn cây trước. *Thuật toán sẽ giảm weight của các samples "không quan trọng", tức những sample mà learner trước đã đoán đúng, và tăng weight của các samples *quan trọng hơn*, tức những samples mà learner trước đoán sai.* Điều này giống như ví dụ ôn Toán ở trên, bạn có ôn lại (nhiều lần) những bài toán mà mình luôn làm đúng không? Vì chiến thuật đúng hơn vẫn là ôn những bài mà chúng ta làm sai nhiều hơn.

## 1.3. Biểu quyết có trọng số (weighted voting)

Khi ta đã hoàn thành việc training với AdaBoost, thứ ta nhận được không chỉ là một tập hợp các base learners (trong bài này sẽ là các cây quyết định) mà còn một tập hợp các trọng số $\alpha$ tương ứng mỗi cây. AdaBoost đưa ra kết quả cuối vẫn bằng phương pháp biểu quyết (majority voting) như RF, nhưng mỗi quyết định của các cây sẽ bị tác động bởi giá trị $\alpha$ tương ứng (sẽ nói rõ phần sau). Tập hợp giá trị $\alpha$ này có thể hiểu là "sức nặng" (amount of say) mỗi biểu quyết của mỗi cây. Giả sử một trường hợp ngoài đời, bạn cần mua một chiếc ô tô nhưng không biết chọn loại nào nên đi khắp nơi hỏi ý kiến mọi người. Bạn gặp 2 người, một người có 30 năm kinh doanh ô tô và anh ta cho rằng bạn nên mua một chiếc Honda, một người là streamer nổi tiếng, chưa có bằng lái và cho rằng bạn nên mua một chiếc Vinfast. Bạn sẽ tin ai? Rõ ràng người bán xe có lời khuyên có sức nặng lớn hơn, hay trong thuật ngữ AdaBoost là có giá trị $\alpha$ lớn hơn, do kinh nghiệm không thể chối cãi của anh ta. Thuật toán áp dụng nguyên lý y như vậy, base learner có kết quả tốt hơn và mạnh hơn thì đóng góp lớn hơn trong kết quả cuối.

# 2. Giải thích thuật toán

Như đã tiết lộ ở trên, AdaBoost giống Random Forest ở chỗ nó cũng tạo một tập hợp các learners và sau đó cho biếu quyết. Vấn đề khác mà ta cần giải quyết đó là AdaBoost sử dụng boosting nên (đại loại) các learners sau phải học trên kết quả của learners trước. Với RF, các cây học độc lập nên chúng ta không cần can thiệp nhiều trong quá trình tính loss và điều chỉnh theo thứ tự như boosting. Phần này sẽ diễn giải cách hoạt động của AdaBoost trong bài toán *phân loại nhị phân* (binary classification).

Trước hết, giả sử ta có một tập dữ liệu $X$ với $N$ samples, và tập targets $Y$ tương ứng. Trong đó $Y\in\set{-1,1}$ thay vì kí hiệu class $0$ và $1$ như thông thường. Thuật toán, được kí hiệu là hàm h(x), sẽ tạo một tập hợp các learners đã train $G=\set{g_1,g_2,...,g_M}$ có $M$ learners và một tập hợp $A=\set{\alpha_1,\alpha_2,...,\alpha_M}$ có $M$ trọng số tương ứng cho từng learner. Vậy để tổng hợp được quyết định cuối cùng thì

$$
\begin{equation}
\begin{aligned}
    G(x) &= \sum_{m=1}^{M}\alpha_m g_m(x) \\
    h(x) &= sign(G(x))
\end{aligned}
\end{equation}
$$

là công thức weighted voting cho AdaBoost với hàm $sign()$ sẽ cho $-1$ nếu nhận giá trị **âm** và $1$ nếu nhận giá trị **dương**. Ta sẽ đặt $f(x)=G(x)$. 

## 2.1. Hàm loss và tối ưu

Như mọi bài toán khác, ta cần một hàm loss. Hiện tại ta sẽ dùng hàm loss $L()$ được cho như sau, lí do sẽ giải thích phần sau.

$$
    L(y,f(x)) = exp(-y f(x)) 
$$

Cũng như mọi bài toán khác, với optimization thì ta cần tìm $min L(y,f(x))$ để kiếm được giá trị tối ưu cho thuật toán. Nghĩa là ta cần tìm 

$$
\begin{equation}
\begin{aligned}
    (A, G) &= argmin \sum_{i=1}^{N} L(y_i, f(x_i)) \\
    (A, G) &= argmin_{\alpha, g} \sum_{i=1}^{N} L(y_i, \sum_{m=1}^{M} \alpha_m g_m(x_i))
\end{aligned}
\end{equation}
$$

Như vậy để tối ưu được model theo cách thông thường sẽ rất tốn kém. Cứ thử tưởng tượng, với mỗi một vòng lặp mới ta cần phải tối ưu một lần, và mỗi lần tối ưu thì sẽ phải chỉnh toàn bộ parameters của các learners đã tạo và learner của vòng lặp này. Để khắc phục vấn đề này thì AdaBoost sử dụng một kiểu thuật toán khác gọi là *(Greedy) Forward Stagewise Modelling* (FSM).

Với FSM, ta chỉ đơn giản là tối ưu learner của vòng lặp hiện tại và giữ nguyên các learners đã tạo trước đó. Như vậy, để tìm parameter tối ưu của learner thứ $m$ thì

$$
    (\alpha_m, g_m) = argmin_{\alpha,g} \sum_{i=1}^{N} exp(-y_i (f_{m-1}(x_i) + \alpha g(x_i))
$$

với $f_{m-1}$ khi khai triển ra sẽ là tổng kết quả các learners trước đó. Ta sẽ tiếp tục khai triển phía trong hàm $argmin$, trong phần tiếp theo tôi xin phép sử dụng $e$ thay vì $exp()$ vì trông nó đẹp hơn. Phần ta cần giải quyết là

$$
\begin{gather}
    \sum_{i=1}^{N} e^{-y_i (f_{m-1}(x_i) + \alpha g(x_i))} \\
    = \sum_{i=1}^{N} e^{-y_i f_{m-1}(x_i)} e^{-y_i \alpha g(x_i)}
\end{gather}
$$

trong đó, ta sẽ tạm đặt $w^{(m)}_i = e^{-y_i f_{m-1}(x_i)}$ vì cụm này chỉ là kết quả của mọi learners trước nên ta sẽ xem là một biến chưa thể can thiệp. Như vậy, ta sẽ có

$$
    \sum_{i=1}^{N} w^{(m)}_i e^{-y_i \alpha g(x_i)}
$$

Còn nhớ $Y\in \set{-1,1}$ chứ? Vì tính chất này mà ta suy ra được $2$ điểm:
   1. Nếu $y_i=g(x_i)$, thì $-y_i g(x_i) < 0$
   2. Nếu $y_i \neq g(x_i)$, thì $-y_i g(x_i) > 0$

Áp dụng $2$ tính chất này vào hàm trên, tạm gọi là $B(x, y)$ và giải thêm thì ta có

$$
\begin{equation}
\begin{aligned}
    B(x,y) 
    &= \sum_{y=g(x)} w^{(m)}_i e^{-\alpha} + \sum_{y \neq g(x)} w^{(m)}_i e^{\alpha} 
    \\
    &= e^{-\alpha} \sum_{i=1}^{N} w^{(m)}_i I(y_i = g(x_i)) + e^{\alpha} \sum_{i=1}^{N} w^{(m)}_i I(y_i \neq g(x_i))
\end{aligned}
\end{equation}
$$

Trong đó, hàm $I()$ trả về $1$ nếu điều kiện đúng và $0$ nếu sai. Theo cách kí hiệu như này, ta dùng tính chất $\sum_{i=1}^{N} I(y_i = g(x_i)) = \sum_{i=1}^{N} - \sum_{i=1}^{N} I(y_i \neq g(x_i))$ thì

$$
\begin{equation}
\begin{aligned}
    B(x,y) 
    &= e^{-\alpha} (\sum_{i=1}^{N} w^{(m)}_i - \sum_{i=1}^{N} w^{(m)}_i I(y_i \neq g(x_i))) + e^{\alpha} \sum_{i=1}^{N} w^{(m)}_i I(y_i \neq g(x_i)) \\
    &= e^{-\alpha} \sum_{i=1}^{N} w^{(m)}_i + (e^{\alpha}-e^{-\alpha}) \sum_{i=1}^{N} w^{(m)}_i I(y_i \neq g(x_i))
\end{aligned}
\end{equation}
$$

Tới đây ta sẽ đặt $T_w=\sum_{i=1}^{N} w^{(m)}_i$ là tổng weight và $Err_w=\sum_{i=1}^{N} w^{(m)}_i I(y_i \neq g(x_i))$ là tổng lỗi. Như vậy khi thế vào công thức tính loss cũ thì ta có

$$
    argmin_\alpha e^{-\alpha} T_w + (e^{\alpha}-e^{-\alpha})Err_w
$$

Để tìm giá trị $\alpha$ tối ưu thì ta đạo hàm và gán bằng $0$ để tìm cực tiểu

$$
\begin{equation}
\begin{aligned}
    \frac{\mathrm{d} L}{\mathrm{d}\alpha} 
    &= -e^{-\alpha}T_w + e^{\alpha}E_w + e^{-\alpha}E_w \\
    0 &= e^{-\alpha}(E_w-T_w) + e^{\alpha}E_w \\
    -e^{\alpha}E_w &= e^{-\alpha}(E_w-T_w) \\
    -e^{2 \alpha} &= \dfrac{E_w-T_w}{E_w} \\
    e^{2 \alpha} &= \dfrac{T_w-E_w}{E_w} \\
    2 \alpha &= ln \dfrac{T_w/T_w-E_w/T_w}{E_w/T_w} \\
    \alpha &= \dfrac{1}{2} ln \dfrac{1 - err_m}{err_m}
\end{aligned}
\end{equation}
$$

trong đó $\dfrac{1}{2}$ là constant nên ta có lược bỏ vì không ảnh hưởng nhiều đến kết quả. $err_m$ vẫn là tổng lỗi của learner thứ $m$ này sau khi đã được normalized với tổng weight.

# Tài liệu tham khảo
[Elements of Statistical Learning](https://link.springer.com/book/10.1007/978-0-387-84858-7)
[https://machinelearningtheory.org/docs/Boosting/adaboost/](https://machinelearningtheory.org/docs/Boosting/adaboost/)
